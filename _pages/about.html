---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
---

{% include base_path %}

<div class="topbar">
    <div class="container">
        <div>
      <div class="row mt-0">
                <br>
      </div>
      <div class="row mt-0" style="padding-bottom: 5px;">
                <div class="col-4 col-sm-4 col-md-3 col-lg-2 p-0 pl-0 pl-sm-4 offset-xl-1 col-xl-7">
                    <h1 class="hidden-xs-down"><span itemprop="name">Mikaela Angelina Uy</span></h1>
                </div>
      </div>
      <div class="row mt-0" style="padding-bottom: 15px;">
                <div class="col-4 col-sm-4 col-md-3 col-lg-2 p-0 pl-0 pl-sm-4 offset-xl-1 col-xl-7">
                    <p>
                        I'm currently a Research Scientist at <a href="https://research.nvidia.com/labs/toronto-ai/">NVIDIA Toronto AI Lab</a> led by <a href="https://www.cs.utoronto.ca/~fidler/">Sanja Filder</a>. I obtained my PhD at Stanford University advised by <a href="https://geometry.stanford.edu/member/guibas/index.html">Leonidas Guibas</a>. Broadly, my research interests are in 3D vision, geometry processing, graphics and machine learning. Specifically, I am interested in diving into different representations of 3D objects and scenes for various downstream tasks such as deformation, reconstruction, controllable generation and variation synthesis. I am particularly drawn to designing methods that connect classical techniques to learning-based approaches that are fundamentally-grounded and mathematically-inspired.

                        <!-- My recent research focuses on 3D shape deformations and variation generation, shape analysis, and geometry processing. My goal is to make 3D content creation universally accessible and useful. -->
                    </p>

                    <p>
                        During my PhD, I was a research intern at Google in the <a href="https://blog.google/technology/research/project-starline/">Project Starline</a> team, <a href="https://research.adobe.com/">Adobe Research</a> and <a href="https://www.autodesk.com/research/overview">Autodesk AI Lab</a>. I was also fortunate to have also closely collaborated with <a href="https://www.sfu.ca/~keli/">Ke Li</a> and <a href="https://mhsung.github.io">Minhyuk Sung</a>, whose advice have also guided me to grow, appreciate and develop my taste in research. 
                    </p>

                    <p>
                        I am grateful to be a recipient of the 2023 <a target="_blank" href="https://machinelearning.apple.com/updates/apple-scholars-aiml-2023">Apple Scholars in AI/ML PhD Fellowship</a> and the 2022 <a target="_blank" href="https://research.snap.com/fellowships">Snap Research Fellowship</a>. I'm also selected as one of the EECS Rising Stars 2023.
                    </p>

                    <p>
                        Previously, I received my Bachelor's degree double majoring in Mathematics and Computer Science from the Hong Kong University of Science and Technology (HKUST) in 2017, and my Master's in Computing from the National University of Singapore in 2018. I then returned to HKUST as a Research Assistant for a year and had the pleasure of working with <a href="http://www.saikit.org/">Sai-Kit Yeung</a>, <a href="https://sonhua.github.io/">Binh-Son Hua</a> and <a href="https://ducthanhnguyen.weebly.com/">Duc Thanh Nguyen</a>.
                    </p>

                    <!-- <p>
                        <b>For highly-motivated students interested in projects related to NeRFs and/or geometry processing and shape analysis please fill out <a target="_blank" href="https://docs.google.com/forms/d/e/1FAIpQLSeOHrQGhQY3J7yfoj5C8VF1-vp5dBDKloId7uld8XgMnK0zlQ/viewform?usp=sf_link">this</a> google form.</b> I am looking for potential collaborators to work on exciting and fundamental problems with!                     
                    </p> -->

                    <p class="my-0">
                      <a href="{{ base_path }}/assets/CV_MikaelaUy_Sept2023.pdf">CV</a> <br>
                      mikacuy [at] gmail [dot] com <br>
                      mikacuy [at] stanford [dot] edu <br>
                      <a href="https://scholar.google.com/citations?user=PcX1zXwAAAAJ&hl=en">Google scholar</a> <br> 
                      <a href="https://github.com/mikacuy/">Github</a> <br>
                      <a href="https://twitter.com/mikacuy">Twitter</a> <br>                      
                    </p>

                    <p class="my-0">
                      Also check out a feature article for <em>Women in Computer Vision</em> from RSIP Vision <a href="https://www.rsipvision.com/CVPR2021-Wednesday/18/">here</a>.
                    </p>
                </div>
            </div>
        </div>
    </div>
</div>


  <!-- ###################### News ######################## -->
  <div class="container">
    <div class="row mb-3">
    
      <div class="col-12 pt-3  px-4 pb-4   bubble offset-xl-1 col-xl-10">
      <h2>News</h2>
        <div class="awards">
        <ul>
          <li> Jun 2025. Three papers accepted to ICCV 2025.</li>
          <li> Jun 2025. Serving as a program committee member at Eurographics 2026.</li>
          <li> May 2025. One paper accepted to TMLR 2025.</li>
          <li> May 2025. Serving as an Area Chair at 3DV 2026.</li>
          <li> Sept 2024. Finished up at Stanford and started full-time at Nvidia.</li>
          <li> Jun 2024. Serving as a program committee member at Eurographics 2025.</li>       
        </ul>
        </div>
    
      </div>
    </div>
    </div>
    <!-- ############################################## -->

  <!-- ####################### Publications ####################### -->
  <h2>Selected Publications</h2>

  <div class="container">
    <div class="row mb-3" style="padding-bottom: 25px;">
    
      <div class="col-12 pt-3  px-4 pb-4   bubble offset-xl-1 col-xl-10" >

        <div class="publication media">
          <img src="{{ base_path }}/assets/images/partfield.png" class="publogo img-fluid float-left rounded g" width="180" <="" a="">
          <div class="media-body">
            <p>
            <strong><a href="https://research.nvidia.com/labs/toronto-ai/partfield-release/">
              PartField: Learning 3D Feature Fields for Part Segmentation and Beyond</a></strong>    
            <br>
            Minghua Liu*, <u>Mikaela Angelina Uy*</u>, Donglai Xiang, Hao Su, Sanja Fidler, Nicholas Sharp, Jun Gao<br>
            <em>ICCV</em>, 2025<br>
            <span class="links">
              <a href="https://research.nvidia.com/labs/toronto-ai/partfield-release/">Project Page</a>
              <a href="https://arxiv.org/abs/2504.11451">Paper</a>
              <a href="https://github.com/nv-tlabs/PartField/tree/main">Code</a>
            </span> <br> </p>
            <br>
          </div>
        </div> 

        <div class="publication media">
          <img src="{{ base_path }}/assets/images/apc-thumbnail.png" class="publogo img-fluid float-left rounded g" width="180" <="" a="">
          <div class="media-body">
            <p>
            <strong><a href="https://apc-vlm.github.io/">
              Perspective-Aware Reasoning in Vision-Language Models via Mental Imagery Simulation</a></strong>    
            <br>
            Phillip Y. Lee, Jihyeon Je, Chanho Park, <u>Mikaela Angelina Uy</u>, Leonidas Guibas, Minhyuk Sung<br>
            <em>ICCV</em>, 2025<br>
            <span class="links">
              <a href="https://apc-vlm.github.io/">Project Page</a>
              <a href="https://arxiv.org/abs/2504.17207">Paper</a>
              <a href="https://github.com/KAIST-Visual-AI-Group/APC-VLM">Code</a>
            </span> <br> </p>
            <br>
          </div>
        </div> 

        <div class="publication media">
          <img src="{{ base_path }}/assets/images/GMC.png" class="publogo img-fluid float-left rounded g" width="180" <="" a="">
          <div class="media-body">
            <p>
            <strong><a href="https://mikacuy.github.io/">
              Global Motion Corresponder for 3D Point-Based Scene Interpolation under Large Motion</a></strong>    
            <br>
            Junru Lin*, Chirag Vashist*, <u>Mikaela Angelina Uy</u>, Colton Stearns, Xuan Luo, Leonidas Guibas, Ke Li<br>
            <em>ICCV</em>, 2025<br>
            <span class="links">
              <a href="https://mikacuy.github.io/">Project Page</a>
              <a href="https://mikacuy.github.io/">Paper</a>
              <a href="https://mikacuy.github.io/">Code</a>
            </span> <br> </p>
            <br>
          </div>
        </div> 

        <div class="publication media">
          <img src="{{ base_path }}/assets/images/dygaubench_opt.gif" class="publogo img-fluid float-left rounded g" width="180" <="" a="">
          <div class="media-body">
            <p>
            <strong><a href="https://arxiv.org/abs/2412.04457">
              Monocular Dynamic Gaussian Splatting is Fast and Brittle and Scene Complexity Rules</a></strong>    
            <br>
            Yiqing Liang, Mikhail Okunev, <u>Mikaela Angelina Uy</u>, Runfeng Li, Leonidas Guibas, James Tompkin, Adam Harley<br>
            <em>TMLR</em>, 2025<br>
            <span class="links">
              <a href="https://arxiv.org/abs/2412.04457">Paper</a>
              <a href="https://onedrive.live.com/?id=4DD35D8EE847A247%21sdb9da2994f59411c8928d856e69a8ae5&cid=4dd35d8ee847a247&ithint=folder&redeem=aHR0cHM6Ly8xZHJ2Lm1zL2YvYy80ZGQzNWQ4ZWU4NDdhMjQ3L0VwbWluZHRaVHh4QmlTallWdWFhaXVVQnI3dzNuT3pFbDZHanJXam1WUHVCRnc%5FZT1jVzVnZzE">Data</a>
              <a href="https://github.com/lynl7130/MonoDyGauBench_code">Code</a>
            </span> <br> </p>
            <br>
          </div>
        </div> 
        

        <div class="publication media">
          <img src="{{ base_path }}/assets/images/provNeRF.png" class="publogo img-fluid float-left rounded g" width="200" <="" a="">
          <div class="media-body">
            <p>
            <strong><a href="https://provnerf.github.io/">
              ProvNeRF: Modeling per Point Provenance in NeRFs as a Stochastic Process</a></strong>    
            <br>
            George Kiyohiro Nakayama, <u>Mikaela Angelina Uy</u>, Yang You, Ke Li, Leonidas Guibas<br>
            <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2024<br>
            <span class="links">
              <a href="https://provnerf.github.io/">Project Page</a>
              <a href="https://arxiv.org/abs/2401.08140">Paper</a>
              <!-- <a href="https://github.com/coltonstearns/dynamic-gaussian-marbles">Code</a> -->
              <!-- Video -->
              <!-- <a href="{{ base_path }}/assets/poster/linear_stanford-berkeley-poster.pdf">Poster</a> -->
      <!--         <a href="https://point2cyl.github.io/">Project Page</a>
            <a href="https://arxiv.org/pdf/2101.07889.pdf">Paper</a>
            <a href="https://github.com/mikacuy/point2cyl">Code</a>
            <a href="https://www.youtube.com/watch?v=4R4Pi8qWXmo">Video</a>
            <a href="https://point2cyl.github.io/assets/cvpr22_poster_final.pdf">Poster</a> -->
            </span> <br> </p>
            <br>
          </div>
        </div> 

  <div class="publication media">
    <img src="{{ base_path }}/assets/images/mv2cyl-thumbnail.png" class="publogo img-fluid float-left rounded g" width="200" <="" a="">
    <div class="media-body">
      <p>
      <strong><a href="https://mikacuy.github.io/">
        	MV2Cyl: Reconstructing 3D Extrusion Cylinders from Multi-View Images</a></strong>    
      <br>
      Eunji Hong, Nguyen Minh Hieu, <u>Mikaela Angelina Uy</u>, Minhyuk Sung<br>
      <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2024<br>
      <span class="links">
        <!-- <a href="https://geometry.stanford.edu/projects/dynamic-gaussian-marbles.github.io/">Project Page</a> -->
        <a href="https://arxiv.org/abs/2406.10853">Paper</a>
        <!-- <a href="https://github.com/coltonstearns/dynamic-gaussian-marbles">Code</a> -->
        <!-- Video -->
        <!-- <a href="{{ base_path }}/assets/poster/linear_stanford-berkeley-poster.pdf">Poster</a> -->
<!--         <a href="https://point2cyl.github.io/">Project Page</a>
      <a href="https://arxiv.org/pdf/2101.07889.pdf">Paper</a>
      <a href="https://github.com/mikacuy/point2cyl">Code</a>
      <a href="https://www.youtube.com/watch?v=4R4Pi8qWXmo">Video</a>
      <a href="https://point2cyl.github.io/assets/cvpr22_poster_final.pdf">Poster</a> -->
      </span> <br> </p>
      <br>
    </div>
  </div>   

  <div class="publication media">
    <img src="{{ base_path }}/assets/images/marble-tiger.gif" class="publogo img-fluid float-left rounded g" width="180" <="" a="">
    <div class="media-body">
      <p>
      <strong><a href="https://geometry.stanford.edu/projects/dynamic-gaussian-marbles.github.io/">
        Dynamic Gaussian Marbles for Novel View Synthesis of Casual Monocular Videos</a></strong>    
      <br>
      Colton Stearns, Adam Harley, <u>Mikaela Angelina Uy</u>, Florian Dubost, Federico Tombari, Gordon Wetzstein, Leonidas Guibas<br>
      <em>SIGGRAPH Asia</em>, 2024<br>
      <span class="links">
        <a href="https://geometry.stanford.edu/projects/dynamic-gaussian-marbles.github.io/">Project Page</a>
        <a href="https://arxiv.org/pdf/2406.18717">Paper</a>
        <a href="https://github.com/coltonstearns/dynamic-gaussian-marbles">Code</a>
        <!-- Video -->
        <!-- <a href="{{ base_path }}/assets/poster/linear_stanford-berkeley-poster.pdf">Poster</a> -->
<!--         <a href="https://point2cyl.github.io/">Project Page</a>
      <a href="https://arxiv.org/pdf/2101.07889.pdf">Paper</a>
      <a href="https://github.com/mikacuy/point2cyl">Code</a>
      <a href="https://www.youtube.com/watch?v=4R4Pi8qWXmo">Video</a>
      <a href="https://point2cyl.github.io/assets/cvpr22_poster_final.pdf">Poster</a> -->
      </span> <br> </p>
      <br>
    </div>
  </div> 

    <div class="publication media">
      <img src="{{ base_path }}/assets/images/density.png" class="publogo img-fluid float-left rounded g" width="200" <="" a="">
      <div class="media-body">
        <p>
        <strong><a href="https://pl-nerf.github.io">
        NeRF Revisited: Fixing Quadrature Instability in Volume Rendering</a></strong>    
        <br>
        <u>Mikaela Angelina Uy</u>, George Kiyohiro Nakayama, Guandao Yang, Rahul Krishna Thomas, Leonidas Guibas, Ke Li<br>
        <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2023 <br>
        <span class="links">
          <a href="https://pl-nerf.github.io">Project Page</a>
          <a href="https://arxiv.org/pdf/2310.20685.pdf">Paper</a>
          <a href="https://github.com/mikacuy/PL-NeRF">Code</a>
          <a href="{{ base_path }}/assets/poster/linear_stanford-berkeley-poster.pdf">Poster</a>
<!--         <a href="https://point2cyl.github.io/">Project Page</a>
        <a href="https://arxiv.org/pdf/2101.07889.pdf">Paper</a>
        <a href="https://github.com/mikacuy/point2cyl">Code</a>
        <a href="https://www.youtube.com/watch?v=4R4Pi8qWXmo">Video</a>
        <a href="https://point2cyl.github.io/assets/cvpr22_poster_final.pdf">Poster</a> -->
        </span> <br> </p>
        <br>
      </div>
    </div> 

  <!-- <h5 class="pt-2 pb-1">Computer Vision</h5> -->
    <div class="publication media">
      <img src="{{ base_path }}/assets/images/diffacto_teaser.png" class="publogo img-fluid float-left rounded g" width="200" <="" a="">
      <div class="media-body">
        <p>
        <strong><a href="https://arxiv.org/abs/2305.01921">
        DiffFacto: Controllable Part-Based 3D Point Cloud Generation with Cross Diffusion</a></strong>
        <br>
        George Kiyohiro Nakayama, <u>Mikaela Angelina Uy</u>, Jiahui Huang, Shi-Min Hu, Ke Li, Leonidas Guibas<br>
        <em>IEEE International Conference on Computer Vision (ICCV)</em>, 2023 <br>
        <span class="links">
          <a href="https://difffacto.github.io">Project Page</a>
          <a href="https://arxiv.org/pdf/2305.01921.pdf">Paper</a>
          <a href="https://github.com/diffFacto/diffFacto">Code</a>
          <a href="https://youtu.be/gwlqiJP5izI">Video</a>
<!--         <a href="https://point2cyl.github.io/">Project Page</a>
        <a href="https://arxiv.org/pdf/2101.07889.pdf">Paper</a>
        <a href="https://github.com/mikacuy/point2cyl">Code</a>
        <a href="https://www.youtube.com/watch?v=4R4Pi8qWXmo">Video</a>
        <a href="https://point2cyl.github.io/assets/cvpr22_poster_final.pdf">Poster</a> -->
        </span> <br> </p>
        <br>
      </div>
    </div>

    <div class="publication media">
      <img src="{{ base_path }}/assets/images/optctrlpoints-thumbnail.png" class="publogo img-fluid float-left rounded g" width="200" <="" a="">
      <div class="media-body">
        <p>
        <strong><a href="https://arxiv.org/abs/2309.12899">OptCtrlPoints: Optimizing Control Points for Biharmonic 3D Shape Deformation</a></strong>
        <br>
        Kunho Kim*, <u>Mikaela Angelina Uy*</u>, Despoina Paschalidou, Alec Jacobson, Leonidas Guibas, Minhyuk Sung<br>
        <em>Pacific Graphics (Full Paper)</em>, 2023 <br>
        <span class="links">
          <a href="https://soulmates2.github.io/publications/OptCtrlPoints/">Project Page</a>
          <a href="https://arxiv.org/pdf/2309.12899.pdf">Paper</a>
          <a href="https://github.com/Soulmates2/OptCtrlPoints">Code</a>
          <a href="https://www.youtube.com/watch?v=5citPk0yRgM">Video</a>
          <a href="https://soulmates2.github.io/publications/OptCtrlPoints/static/OptCtrlPoints_slides.pptx">Slides</a>
<!--         <a href="https://point2cyl.github.io/">Project Page</a>
        <a href="https://arxiv.org/pdf/2101.07889.pdf">Paper</a>
        <a href="https://github.com/mikacuy/point2cyl">Code</a>
        <a href="https://www.youtube.com/watch?v=4R4Pi8qWXmo">Video</a>
        <a href="https://point2cyl.github.io/assets/cvpr22_poster_final.pdf">Poster</a> -->
        </span> <br> </p>
        <br>
      </div>
    </div>    

  <!-- <h5 class="pt-2 pb-1">Computer Vision</h5> -->
    <div class="publication media">
      <img src="{{ base_path }}/assets/images/scade_teaser.png" class="publogo img-fluid float-left rounded g" width="200" <="" a="">
      <div class="media-body">
        <p>
        <strong><a href="https://arxiv.org/abs/2303.13582">
        SCADE: NeRFs from Space Carving with Ambiguity-Aware Depth Estimates</a></strong>
        <br>
        <u>Mikaela Angelina Uy</u>, Ricardo Martin-Brualla, Leonidas Guibas, Ke Li<br>
        <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023  <br>
        <span class="links">
          <a href="https://scade-spacecarving-nerfs.github.io/">Project Page</a>
          <a href="https://arxiv.org/pdf/2303.13582.pdf">Paper</a>
          <a href="https://github.com/mikacuy/scade">Code</a>
          <a href="https://www.youtube.com/watch?v=5XwWZn-kjBU">Video</a>
        <!-- <a href="https://point2cyl.github.io/assets/cvpr22_poster_final.pdf">Poster</a> -->
        </span> <br> </p>
        <br>
      </div>
    </div>

    <div class="publication media">
      <img src="{{ base_path }}/assets/images/partnerf_teaser.png" class="publogo img-fluid float-left rounded g" width="200" <="" a="">
      <div class="media-body">
        <p>
        <strong><a href="https://arxiv.org/abs/2303.09554">
        PartNeRF: Generating Part-Aware Editable 3D Shapes without 3D Supervision</a></strong>
        <br>
        Konstaninos Tertikas, Despoina Paschalidou, Boxiao Pan, Jeong Joon Park, <u>Mikaela Angelina Uy</u>, Ioannis Emiris, Yannis Avrithis, Leonidas Guibas<br>
        <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023  <br>
        <span class="links">
          <a href="https://ktertikas.github.io/part_nerf">Project Page</a>
          <a href="https://arxiv.org/pdf/2303.09554.pdf">Paper</a>
        </span> <br> </p>
        <br>
      </div>
    </div>

    <div class="publication media">
      <img src="{{ base_path }}/assets/images/cvpr22_point2cyl.jpg" class="publogo img-fluid float-left rounded g" width="200" <="" a="">
      <div class="media-body">
        <p>
        <strong><a href="https://arxiv.org/abs/2112.09329">
        Point2Cyl: Reverse Engineering 3D Objects from Point Clouds to Extrusion Cylinders</a></strong>
        <!-- <span class="badge badge-danger">New!</span> -->
        <br>
        <u>Mikaela Angelina Uy*</u>, Yen-yu Chang*, Minhyuk Sung, Purvi Goel, Joseph Lambourne, Tolga Birdal, Leonidas Guibas<br>
        <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2022  <br>
        <span class="links">
        <a href="https://point2cyl.github.io/">Project Page</a>
        <a href="https://arxiv.org/pdf/2112.09329.pdf">Paper</a>
        <a href="https://github.com/mikacuy/point2cyl">Code</a>
        <a href="https://www.youtube.com/watch?v=4R4Pi8qWXmo">Video</a>
        <a href="https://point2cyl.github.io/assets/cvpr22_poster_final.pdf">Poster</a>
        </span> <br> </p>
        <br>
      </div>
    </div>

    <div class="publication media">
      <img src="{{ base_path }}/assets/images/21_CVPR_RetrieveAndDeform.jpg" class="publogo img-fluid float-left rounded g" width="200" <="" a="">
      <div class="media-body">
        <p>
        <strong><a href="https://arxiv.org/abs/2101.07889">
        Joint Learning of 3D Shape Retrieval and Deformation</a></strong>
        <!-- <span class="badge badge-danger">New!</span> -->
        <br>
        <u>Mikaela Angelina Uy</u>, Vladimir G. Kim, Minhyuk Sung, Noam Aigerman, Siddhartha Chaudhuri, Leonidas Guibas<br>
        <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2021  <br>
        <span class="links">
        <a href="https://joint-retrieval-deformation.github.io/">Project Page</a>
        <a href="https://arxiv.org/pdf/2101.07889.pdf">Paper</a>
        <a href="https://github.com/mikacuy/joint_learning_retrieval_deformation">Code</a>
        <a href="https://youtu.be/ZeDJLHdCpUQ">Video</a>
        <a href="https://joint-retrieval-deformation.github.io/assets/cvpr21_joint_poster_v3.pdf">Poster</a>
        </span> <br> </p>
        <br>
      </div>
    </div>


    <div class="publication media">
      <img src="{{ base_path }}/assets/images/embedding_v2.png" class="publogo img-fluid float-left rounded g" width="200" <="" a="">
      <div class="media-body">
        <p>
        <strong><a href="https://deformscan2cad.github.io/">
        Deformation-Aware 3D Model Embedding and Retrieval</a></strong>
        <!-- <span class="badge badge-danger">New!</span> -->
        <br>
        <u>Mikaela Angelina Uy</u>, Jingwei Huang, Minhyuk Sung, Tolga Birdal, Leonidas Guibas<br>
        <em>European Conference on Computer Vision (ECCV)</em>, 2020 <br>
        <span class="links">
        <a href="https://deformscan2cad.github.io/">Project Page</a>
        <a href="https://arxiv.org/pdf/2004.01228.pdf">Paper</a>
        <a href="https://github.com/mikacuy/deformation_aware_embedding">Code</a>
        <a href="https://www.youtube.com/embed/u_8DJ06SQdw">10-min Video</a>
        <a href="https://www.youtube.com/embed/O0FAOx-npc8">1-min Video</a>
        </span> <br> </p>
        <br>
      </div>
    </div>

    <div class="publication media">
      <img src="{{ base_path }}/assets/images/lcd_teaser.jpg" class="publogo img-fluid float-left rounded g" width="200" <="" a="">
      <div class="media-body">
        <p>
        <strong><a href="https://hkust-vgd.github.io/lcd/">
        LCD: Learned Cross-Domain Descriptors for 2D-3D Matching</a></strong>
        <!-- <span class="badge badge-danger">New!</span> -->
        <br>
        Quang-Hieu Pham, <u>Mikaela Angelina Uy</u>, Binh-Son Hua, Duc Thanh Nguyen, Gemma Roig, Sai-Kit Yeung<br>
        <em>AAAI Conference on Artificial Intelligence (AAAI)</em>, 2020 <b>(Oral)</b> <br> 
        <span class="links">
        <a href="https://hkust-vgd.github.io/lcd/">Project Page</a>
        <a href="https://arxiv.org/pdf/1911.09326.pdf">Paper</a>
        <a href="https://github.com/hkust-vgd/lcd">Code</a>
        </span> <br> </p>
      </div>
    </div>

    <div class="publication media">
      <br>
      <img src="{{ base_path }}/assets/images/objects_teaser.png" class="publogo img-fluid float-left rounded g" width="200" <="" a="">
      <div class="media-body">
        <p><strong><a href="https://hkust-vgd.github.io/scanobjectnn/">
        Revisiting Point Cloud Classification: A New Benchmark Dataset and Classification Model on Real-World Data</a></strong>
        <!-- <span class="badge badge-danger">New!</span> -->
        <br>
        <u>Mikaela Angelina Uy</u>, Quang-Hieu Pham, Binh-Son Hua, Duc Thanh Nguyen, Sai-Kit Yeung<br>
        <em>IEEE International Conference on Computer Vision (ICCV)</em>, 2019 <b>(Oral)</b> <br>
        <span class="links">
        <a href="https://hkust-vgd.github.io/scanobjectnn/">Project Page</a>
        <a href="https://arxiv.org/pdf/1908.04616.pdf">Paper</a>
        <a href="{{ base_path }}/assets/papers/uy_iccv19_supp.pdf">Supplementary</a>
        <a href="https://github.com/hkust-vgd/scanobjectnn">Code</a>
        <a href="{{ base_path }}/assets/poster/iccv2019_poster_v2.pdf">Poster</a>
        </span> </p>
      </div>
    </div>

<!--     <div class="publication media">
      <img src="{{ base_path }}/assets/images/pointnetvlad_teaser.png" class="publogo img-fluid float-left rounded g" width="200" <="" a="">
      <div class="media-body">
        <p><strong><a href="https://github.com/mikacuy/pointnetvlad">
        PointNetVLAD: Deep Point Cloud Based Retrieval for Large-Scale Place Recognition</a></strong>
        <br>
        <u>Mikaela Angelina Uy</u>, Gim Hee Lee<br>
        <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2018 <br>
        <span class="links">
        <a href="https://arxiv.org/pdf/1804.03492.pdf">Paper</a>
        <a href="https://github.com/mikacuy/pointnetvlad">Code</a>
        <a href="https://drive.google.com/open?id=1u4lXs9fTJGz_Ch05LeBqi8nT3o96V8OD">Poster</a>
        </span> </p>
      </div>
    </div> -->


  </div>
</div>
</div>


<!-- ############################################## -->
<!-- <div class="container">
<div class="row mb-3" style="padding-bottom: 25px;">

  <div class="col-12 pt-3  px-4 pb-4   bubble offset-xl-1 col-xl-10" >

  <h2>Work Experiences</h2>

  <div class="publication media">
      <img src="{{ base_path }}/assets/images/google-logo.png" class="publogo img-fluid float-left rounded g" width="75" <="" a=""> 
      <div class="media-body">            
        <h3 class="mb-0">Research Intern, Google</h3>
        <div class="subheading mb-3">June - December 2023</div>
                         
        Mentors:
        <a target="_blank" href="https://www.sfu.ca/~keli/"> Ke Li</a>, <a target="_blank" href="https://roxanneluo.github.io/"> Xuan Luo</a>, <a target="_blank" href="https://zhengqili.github.io"> Zhengqi Li</a>
      </div>
  </div>

  <div class="publication media">
      <img src="{{ base_path }}/assets/images/google-logo.png" class="publogo img-fluid float-left rounded g" width="75" <="" a=""> 
      <div class="media-body">            
        <h3 class="mb-0">Research Intern, Project Starline, Google</h3>
        <div class="subheading mb-3">June 2022 - January 2023</div>
                         
        Mentors:
        <a target="_blank" href="https://www.sfu.ca/~keli/"> Ke Li</a>, Mirko Visontai 
      </div>
  </div>

  <div class="publication media">
      <img src="{{ base_path }}/assets/images/autodesk.png" class="publogo img-fluid float-left rounded g" width="75" <="" a=""> 
      <div class="media-body">            
        <h3 class="mb-0">Research Intern, Autodesk AI Lab</h3>
        <div class="subheading mb-3">June - September 2021</div>
                         
        Mentors:
        <a target="_blank" href="https://www.autodesk.com/research/people/joseph-lambourne"> Joseph Lambourne</a>
      </div>
  </div>

  <div class="publication media">
      <img src="{{ base_path }}/assets/images/adobe_logo.png" class="publogo img-fluid float-left rounded g" width="75" <="" a=""> 
      <div class="media-body">            
        <h3 class="mb-0">Research Intern, Creative Intelligence Lab, Adobe Research</h3>
        <div class="subheading mb-3">June - September 2020</div>
                         
        Mentors:
        <a target="_blank" href="http://www.vovakim.com"> Vladimir G. Kim</a>,  
        <a target="_blank" href="https://mhsung.github.io"> Minhyuk Sung</a>, 
        <a target="_blank" href="https://noamaig.github.io"> Noam Aigerman</a>, 
        <a target="_blank" href="https://www.cse.iitb.ac.in/~sidch/"> Siddhartha Chaudhuri</a> 
      </div>
  </div>

  <div class="publication media">
      <img src="{{ base_path }}/assets/images/hkust_logo.png" class="publogo img-fluid float-left rounded g" width="75" <="" a=""> 
      <div class="media-body">            
        <h3 class="mb-0"> <br> Research Assistant, Vision & Graphics Group, HKUST</h3>
        <div class="subheading mb-3">September 2018 - June 2019</div>
                         
        Mentors:
        <a target="_blank" href="http://www.saikit.org"> Prof. Sai-Kit Yeung</a>,  
        <a target="_blank" href="https://sonhua.github.io"> Binh-Son Hua</a>, 
        <a target="_blank" href="https://ducthanhnguyen.weebly.com"> Duc Thanh Nguyen</a> 
      </div>
  </div>

  </div>
</div>
</div> -->
<!-- ############################################## -->

<!-- ############################################## -->
<div class="container">
  <div class="row mb-3">
  
    <div class="col-12 pt-3  px-4 pb-4   bubble offset-xl-1 col-xl-10">

    <h2>Invited Talks</h2>
      <div class="awards">
      <ul> 
        <li>Apple Machine Learning Research (MLR), September 7, 2023, Towards Controllable 3D Content Creation by Leveraging Geometric Priors</li>
        <li>Google, July 12, 2023, NeRF Revisited: Fixing Quadrature Instability in Volume Rendering</li>
        <li>SFU Visual Computing and Robotics (VCR) Seminar, June 26, 2023, Towards Controllable 3D Content Creation by Leveraging Geometric Priors</li>
        <li><a target="_blank" href="https://struco3d.github.io/cvpr2023/">Structural and Compositional Learning on 3D Data</a>, CVPR 2023 Workshop, June 18, 2023, Towards Controllable 3D Content Creation by Leveraging Geometric Priors</li>
        <li>KAIST, January 9, 2023, SCADE: NeRFs from Space Carving with Ambiguity-Aware Depth Estimates</li>     
        <li>VinAI Seminar Series, July 22, 2022, Learning to Vary 3D Models for Universally Accessible 3D Content Creation</li>
        <li>Brown Vision Computing Seminar, April 11, 2022, Learning to Vary 3D Models for Universally Accessible 3D Content Creation</li>
        <li>Stanford G-Cafe, March 10, 2022, Point2Cyl: Reverse Engineering 3D Objects from Point Clouds to Extrusion Cylinders</li>
      </ul>
      </div>
  
    </div>
  </div>
  </div>
  <!-- ############################################## -->
  
  <!-- ############################################## -->
  <div class="container">
  <div class="row mb-3">
  
    <div class="col-12 pt-3  px-4 pb-4   bubble offset-xl-1 col-xl-10">

    <h2>Selected Awards</h2>
      <div class="awards">
      <ul>
        <li>EECS Rising Stars, <em> 2023</em> </li>      
        <li><a target="_blank" href="https://machinelearning.apple.com/updates/apple-scholars-aiml-2023">Apple Scholars in AI/ML PhD Fellowship</a>, <em> 2023</em> </li>      
        <li><a target="_blank" href="https://research.snap.com/fellowships">Snap Research Fellowship</a>, <em> 2022</em> </li>
        <li><a target="_blank" href="https://research.facebook.com/blog/2023/4/announcing-the-2023-meta-research-phd-fellowship-award-winners/">Meta PhD Fellowship Finalist</a>, <em> 2023</em> </li>
        <li>School of Engineering Fellowship, <em>Stanford University, 2019-2020</em> </li>
        <li>HKSAR Government Targeted Scholarship (Full 4-year university scholarship)</li>
        <li>NUS Graduate Scholarship for ASEAN Nationals (Full masters scholarship)</li>
        <li>Google Women Techmakers Scholarship, <em>2016</em></li>
        <li>Epsilon Fund Award, <em>HKUST Mathematics Department, 2017</em></li>
        <li>International Mathematical Olympiad (IMO) Bronze Medalist, <em>2012, 2013</em></li>
        <li>Philippine Mathematical Olympiad 1st runner-up, <em>2012, 2013</em></li>
      </ul>
      </div>
  
    </div>
  </div>
  </div>
  <!-- ############################################## -->

<!-- ############################################## -->
<div class="container">
<div class="row mb-3">

  <div class="col-12 pt-3  px-4 pb-4   bubble offset-xl-1 col-xl-10">

  <h2>Teaching Experiences</h2>
    <div class="awards">
    <ul>
      <li>Stanford CS 348n Guest Lecture, May 31, 2023, Neural Radiance Fields: Sparse View and Dynamic Scenes</li> 
      <li>Stanford CS 348n Guest Lecture, May 24, 2023, Continuous and Discrete Shape Edits/Deformations</li>
      <li>Stanford CS 348n Guest Lecture, February 16, 2022, Neural Shape Variation and Generation</li>
      <li>Teaching Assistant, Winter 2021, <a target="_blank" href="http://graphics.stanford.edu/courses/cs348a-21-winter/">Computer Graphics: Geometric Modeling/Processing (CS 348a)</a>, Stanford University</li>
    </ul>
    </div>

  </div>
</div>
</div>
<!-- ############################################## -->

<!-- ############################################## -->
<!-- <div class="container">
<div class="row mb-3">

  <div class="col-12 pt-3  px-4 pb-4   bubble offset-xl-1 col-xl-10">

  <h2>Projects</h2>
  <div class="projects">
      <div class="projects d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <img src="{{ base_path }}/assets/images/cs229_poster.png" class="publogo img-fluid float-left rounded g" width="200" <="" a="">            
              <h3 class="mb-0">Interpretable & Actionable Models using Attribute & Uncertainty Information</h3>
              <div class="subheading mb-3">CS229 project, Autumn 2019</div>

              <ul>
                <li> Deep-learning models can be difficult to understand and control intuitively due to the black-box nature of these models. However, such lack of interpretability and human actionability in the models’ decision processes make it difficult to trust these models in critical applications that affect the lives of people. We propose to alleviate these problems through the use of attribute and uncertainty models in deep networks.</li>
              </ul> 
                               
                Links:
                <a target="_blank" href="{{ base_path }}/assets/papers/CS229_Final_Report.pdf"> Report</a> 
                <a target="_blank" href="{{ base_path }}/assets/poster/cs229_poster.pdf"> Poster</a> 
            </div>
      </div>

      <div class="projects d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <img src="{{ base_path }}/assets/images/epoxsea_logo.png" class="publogo img-fluid float-left rounded g" width="200" <="" a="">            
              <h3 class="mb-0">HKUST Robotics Team, Remotely Operated Vehicle (ROV) Subteam</h3>
              <div class="subheading mb-3">Software Engineer, 2014-2015</div>
                  <ul>
                    <li><b>Overall 3rd Place </b> (Explorer Class) – 14th Annual MATE International Underwater
                          Robotics Competition in <em>St John’s, Newfoundland and Labrador, Canada</em></li>
                    <li><b>Asia Champion</b> in 2015 MATE Asia Regional Underwater Robotics Competition</li>
                    <li>Built the main control software of the ROV, which operates with ROS and is controlled with an Xbox controller, and Qt GUI’s for the competition runs</li>
                    <li>The team is composed of 15 engineers who built and designed the ROV from scratch.</li>
                  </ul>
                Links:
                <a target="_blank" href="https://www.youtube.com/watch?v=tYRYdTxP_7Y"> Video </a> 
            </div>
      </div>

      <div class="projects d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">     
              <h3 class="mb-0">Underwater Object Detection</h3>
              <div class="subheading mb-3">Undergraduate Thesis, HKUST</div>
                  <ul>
                    <li>Advised by <a href="http://www.cs.ust.hk/~cktang/">Prof. Chi-Keung Tang</a></li>
                    <li>Studied the performance of real-time object detection models, both using handcrafted
                    features and deep learning networks, for underwater diver detection in robotics applications</li>
                  </ul>
                Links:
                <a target="_blank" href="{{ base_path }}/assets/poster/FYT_poster.pdf"> Poster </a> 
            </div>
      </div>


  </div>

  </div>
</div>
</div> -->
<!-- ############################################## -->

<!-- ############################################## -->
<div class="container">
  <div class="row mb-3">
  
    <div class="col-12 pt-3  px-4 pb-4   bubble offset-xl-1 col-xl-10">
    <h2>Academic Services</h2>
      <div class="hobbies">
      
      <p>
        Reviewer: CVPR, ICCV, ECCV, SIGGRAPH, SIGGRAPH Asia, BMVC, 3DV, AAAI, TVCG, Eurographics, Pacific Graphics, Neurips, ICLR
      </p>
  
      </div>
  
    </div>
  </div>
  </div>
  <!-- ############################################## -->

<!-- ############################################## -->
<div class="container">
<div class="row mb-3">

  <div class="col-12 pt-3  px-4 pb-4   bubble offset-xl-1 col-xl-10">
  <h2>Hobbies and Interests</h2>
    <div class="hobbies">
    <p>
      For most of my pre-university life, I was into competitive mathematics, with geometry being a favorite topic. I competed in various math competitions both local and abroad representing the Philippine Team. During my spare time back at home, I now train elementary and high school students for international math competitions. I was part of the training team of the 2017-2020 PH IMO team, and I led the PH team to a number of elementary math competitions. <br>
      <br>
      Outside of work, I enjoy bouldering, hiking, cooking and scuba diving. I was also part of the HKUST Women's Soccer Team back in undergrad.

    </p>
    </div>

  </div>
</div>
</div>
<!-- ############################################## -->



