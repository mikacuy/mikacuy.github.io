---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
---

{% include base_path %}

<div class="topbar">
    <div class="container">
        <div>
      <div class="row mt-0">
                <br>
      </div>
      <div class="row mt-0" style="padding-bottom: 5px;">
                <div class="col-4 col-sm-4 col-md-3 col-lg-2 p-0 pl-0 pl-sm-4 offset-xl-1 col-xl-7">
                    <h1 class="hidden-xs-down"><span itemprop="name">Mikaela Angelina Uy</span></h1>
                </div>
      </div>
      <div class="row mt-0" style="padding-bottom: 15px;">
                <div class="col-4 col-sm-4 col-md-3 col-lg-2 p-0 pl-0 pl-sm-4 offset-xl-1 col-xl-7">
                    <p>
                        I am a fourth year PhD student at Stanford University advised by <a href="https://geometry.stanford.edu/member/guibas/index.html">Leonidas Guibas</a>. I am generally interested in computer vision, graphics and machine learning. My recent research focuses on the representation and generation of objects/scenes for 3D content creation. Specifically, I have worked on mesh deformations, CAD models and neural fields.  My goal is to achieve high-quality photorealistic reconstruction and user-controllable 3D generation.

                        <!-- My recent research focuses on 3D shape deformations and variation generation, shape analysis, and geometry processing. My goal is to make 3D content creation universally accessible and useful. -->
                    </p>

                    <p>
                        I am a returning research intern at Google this summer in the <a href="https://blog.google/technology/research/project-starline/">Project Starline</a> team, and was also previously a research intern in <a href="https://research.adobe.com/">Adobe Research</a> and <a href="https://www.autodesk.com/research/overview">Autodesk AI Lab</a>. Throughout the coarse of my PhD, I am very fortunate to have closely worked with <a href="https://mhsung.github.io">Minhyuk Sung</a> and <a href="https://www.sfu.ca/~keli/">Ke Li</a>, whose advice have guided me to appreciate and develop my taste in research. I am also grateful to be a recipient of the 2023 <a target="_blank" href="https://machinelearning.apple.com/updates/apple-scholars-aiml-2023">Apple Scholars in AI/ML PhD Fellowship</a> and the 2022 <a target="_blank" href="https://research.snap.com/fellowships">Snap Research Fellowship</a>. 

                    </p>

                    <p>
                        I received my Bachelor's degree double majoring in Mathematics and Computer Science from the Hong Kong University of Science and Technology (HKUST) in 2017, and my Master's in Computing from the National University of Singapore in 2018. I then returned to HKUST as a Research Assistant for a year and had the pleasure of working with <a href="http://www.saikit.org/">Sai-Kit Yeung</a>, <a href="https://sonhua.github.io/">Binh-Son Hua</a> and <a href="https://ducthanhnguyen.weebly.com/">Duc Thanh Nguyen</a>.
                    </p>

                    <p>
                        <b>For highly-motivated students interested in projects related to NeRFs and/or geometry processing and shape analysis please fill out <a target="_blank" href="https://docs.google.com/forms/d/e/1FAIpQLSeOHrQGhQY3J7yfoj5C8VF1-vp5dBDKloId7uld8XgMnK0zlQ/viewform?usp=sf_link">this</a> google form.</b> I am looking for potential collaborators to work on exciting and fundamental problems with!                     
                    </p>

                    <p class="my-0">
                      <a href="{{ base_path }}/assets/CV_MikaelaUy_Jul2023.pdf">CV</a> <br>
                      mikacuy [at] gmail [dot] com <br>
                      mikacuy [at] stanford [dot] edu <br>
                      <a href="https://scholar.google.com/citations?user=PcX1zXwAAAAJ&hl=en">Google scholar</a> 
                    </p>

                    <p class="my-0">
                      Also check out a feature article for <em>Women in Computer Vision</em> from RSIP Vision <a href="https://www.rsipvision.com/CVPR2021-Wednesday/18/">here</a>.
                    </p>

                </div>

            </div>
        </div>
    </div>
</div>

<div class="container">
<div class="row mb-3" style="padding-bottom: 25px;">

  <div class="col-12 pt-3  px-4 pb-4   bubble offset-xl-1 col-xl-10" >

  <!-- ####################### Publications ####################### -->
  <h2>Selected Publications</h2>

  <!-- <h5 class="pt-2 pb-1">Computer Vision</h5> -->
    <div class="publication media">
      <img src="{{ base_path }}/assets/images/diffacto_teaser.png" class="publogo img-fluid float-left rounded g" width="200" <="" a="">
      <div class="media-body">
        <p>
        <strong><a href="https://arxiv.org/abs/2305.01921">
        DiffFacto: Controllable Part-Based 3D Point Cloud Generation with Cross Diffusion</a></strong>
        <br>
        Kiyohiro Nakayama, <u>Mikaela Angelina Uy</u>, Jiahui Huang, Shi-Min Hu, Ke Li, Leonidas Guibas<br>
        <em>Under submission</em><br>
        <span class="links">
          <a href="https://difffacto.github.io">Project Page</a>
          <a href="https://arxiv.org/pdf/2305.01921.pdf">Paper</a>
          Code
          Video
<!--         <a href="https://point2cyl.github.io/">Project Page</a>
        <a href="https://arxiv.org/pdf/2101.07889.pdf">Paper</a>
        <a href="https://github.com/mikacuy/point2cyl">Code</a>
        <a href="https://www.youtube.com/watch?v=4R4Pi8qWXmo">Video</a>
        <a href="https://point2cyl.github.io/assets/cvpr22_poster_final.pdf">Poster</a> -->
        </span> <br> </p>
        <br>
      </div>
    </div>

  <!-- <h5 class="pt-2 pb-1">Computer Vision</h5> -->
    <div class="publication media">
      <img src="{{ base_path }}/assets/images/scade_teaser.png" class="publogo img-fluid float-left rounded g" width="200" <="" a="">
      <div class="media-body">
        <p>
        <strong><a href="https://arxiv.org/abs/2303.13582">
        SCADE: NeRFs from Space Carving with Ambiguity-Aware Depth Estimates</a></strong>
        <br>
        <u>Mikaela Angelina Uy</u>, Ricardo Martin-Brualla, Leonidas Guibas, Ke Li<br>
        <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023  <br>
        <span class="links">
          <a href="https://scade-spacecarving-nerfs.github.io/">Project Page</a>
          <a href="https://arxiv.org/pdf/2303.13582.pdf">Paper</a>
          <a href="https://github.com/mikacuy/scade">Code</a>
          <a href="https://www.youtube.com/watch?v=5XwWZn-kjBU">Video</a>
        <!-- <a href="https://point2cyl.github.io/assets/cvpr22_poster_final.pdf">Poster</a> -->
        </span> <br> </p>
        <br>
      </div>
    </div>

    <div class="publication media">
      <img src="{{ base_path }}/assets/images/partnerf_teaser.png" class="publogo img-fluid float-left rounded g" width="200" <="" a="">
      <div class="media-body">
        <p>
        <strong><a href="https://arxiv.org/abs/2303.09554">
        PartNeRF: Generating Part-Aware Editable 3D Shapes without 3D Supervision</a></strong>
        <br>
        Konstaninos Tertikas, Despoina Paschalidou, Boxiao Pan, Jeong Joon Park, <u>Mikaela Angelina Uy</u>, Ioannis Emiris, Yannis Avrithis, Leonidas Guibas<br>
        <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023  <br>
        <span class="links">
          <a href="https://ktertikas.github.io/part_nerf">Project Page</a>
          <a href="https://arxiv.org/pdf/2303.09554.pdf">Paper</a>
        </span> <br> </p>
        <br>
      </div>
    </div>

    <div class="publication media">
      <img src="{{ base_path }}/assets/images/cvpr22_point2cyl.jpg" class="publogo img-fluid float-left rounded g" width="200" <="" a="">
      <div class="media-body">
        <p>
        <strong><a href="https://arxiv.org/abs/2112.09329">
        Point2Cyl: Reverse Engineering 3D Objects from Point Clouds to Extrusion Cylinders</a></strong>
        <!-- <span class="badge badge-danger">New!</span> -->
        <br>
        <u>Mikaela Angelina Uy</u><sup>*</sup>, Yen-yu Chang<sup>*</sup>, Minhyuk Sung, Purvi Goel, Joseph Lambourne, Tolga Birdal, Leonidas Guibas<br>
        <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2022  <br>
        <span class="links">
        <a href="https://point2cyl.github.io/">Project Page</a>
        <a href="https://arxiv.org/pdf/2112.09329.pdf">Paper</a>
        <a href="https://github.com/mikacuy/point2cyl">Code</a>
        <a href="https://www.youtube.com/watch?v=4R4Pi8qWXmo">Video</a>
        <a href="https://point2cyl.github.io/assets/cvpr22_poster_final.pdf">Poster</a>
        </span> <br> </p>
        <br>
      </div>
    </div>

    <div class="publication media">
      <img src="{{ base_path }}/assets/images/21_CVPR_RetrieveAndDeform.jpg" class="publogo img-fluid float-left rounded g" width="200" <="" a="">
      <div class="media-body">
        <p>
        <strong><a href="https://arxiv.org/abs/2101.07889">
        Joint Learning of 3D Shape Retrieval and Deformation</a></strong>
        <!-- <span class="badge badge-danger">New!</span> -->
        <br>
        <u>Mikaela Angelina Uy</u>, Vladimir G. Kim, Minhyuk Sung, Noam Aigerman, Siddhartha Chaudhuri, Leonidas Guibas<br>
        <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2021  <br>
        <span class="links">
        <a href="https://joint-retrieval-deformation.github.io/">Project Page</a>
        <a href="https://arxiv.org/pdf/2101.07889.pdf">Paper</a>
        <a href="https://github.com/mikacuy/joint_learning_retrieval_deformation">Code</a>
        <a href="https://youtu.be/ZeDJLHdCpUQ">Video</a>
        <a href="https://joint-retrieval-deformation.github.io/assets/cvpr21_joint_poster_v3.pdf">Poster</a>
        </span> <br> </p>
        <br>
      </div>
    </div>


    <div class="publication media">
      <img src="{{ base_path }}/assets/images/embedding_v2.png" class="publogo img-fluid float-left rounded g" width="200" <="" a="">
      <div class="media-body">
        <p>
        <strong><a href="https://deformscan2cad.github.io/">
        Deformation-Aware 3D Model Embedding and Retrieval</a></strong>
        <!-- <span class="badge badge-danger">New!</span> -->
        <br>
        <u>Mikaela Angelina Uy</u>, Jingwei Huang, Minhyuk Sung, Tolga Birdal, Leonidas Guibas<br>
        <em>European Conference on Computer Vision (ECCV)</em>, 2020 <br>
        <span class="links">
        <a href="https://deformscan2cad.github.io/">Project Page</a>
        <a href="https://arxiv.org/pdf/2004.01228.pdf">Paper</a>
        <a href="https://github.com/mikacuy/deformation_aware_embedding">Code</a>
        <a href="https://www.youtube.com/embed/u_8DJ06SQdw">10-min Video</a>
        <a href="https://www.youtube.com/embed/O0FAOx-npc8">1-min Video</a>
        </span> <br> </p>
        <br>
      </div>
    </div>

    <div class="publication media">
      <img src="{{ base_path }}/assets/images/lcd_teaser.jpg" class="publogo img-fluid float-left rounded g" width="200" <="" a="">
      <div class="media-body">
        <p>
        <strong><a href="https://hkust-vgd.github.io/lcd/">
        LCD: Learned Cross-Domain Descriptors for 2D-3D Matching</a></strong>
        <!-- <span class="badge badge-danger">New!</span> -->
        <br>
        Quang-Hieu Pham, <u>Mikaela Angelina Uy</u>, Binh-Son Hua, Duc Thanh Nguyen, Gemma Roig, Sai-Kit Yeung<br>
        <em>AAAI Conference on Artificial Intelligence (AAAI)</em>, 2020 <b>(Oral)</b> <br> 
        <span class="links">
        <a href="https://hkust-vgd.github.io/lcd/">Project Page</a>
        <a href="https://arxiv.org/pdf/1911.09326.pdf">Paper</a>
        <a href="https://github.com/hkust-vgd/lcd">Code</a>
        </span> <br> </p>
      </div>
    </div>

    <div class="publication media">
      <br>
      <img src="{{ base_path }}/assets/images/objects_teaser.png" class="publogo img-fluid float-left rounded g" width="200" <="" a="">
      <div class="media-body">
        <p><strong><a href="https://hkust-vgd.github.io/scanobjectnn/">
        Revisiting Point Cloud Classification: A New Benchmark Dataset and Classification Model on Real-World Data</a></strong>
        <!-- <span class="badge badge-danger">New!</span> -->
        <br>
        <u>Mikaela Angelina Uy</u>, Quang-Hieu Pham, Binh-Son Hua, Duc Thanh Nguyen, Sai-Kit Yeung<br>
        <em>IEEE International Conference on Computer Vision (ICCV)</em>, 2019 <b>(Oral)</b> <br>
        <span class="links">
        <a href="https://hkust-vgd.github.io/scanobjectnn/">Project Page</a>
        <a href="https://arxiv.org/pdf/1908.04616.pdf">Paper</a>
        <a href="{{ base_path }}/assets/papers/uy_iccv19_supp.pdf">Supplementary</a>
        <a href="https://github.com/hkust-vgd/scanobjectnn">Code</a>
        <a href="{{ base_path }}/assets/poster/iccv2019_poster_v2.pdf">Poster</a>
        </span> </p>
      </div>
    </div>

<!--     <div class="publication media">
      <img src="{{ base_path }}/assets/images/pointnetvlad_teaser.png" class="publogo img-fluid float-left rounded g" width="200" <="" a="">
      <div class="media-body">
        <p><strong><a href="https://github.com/mikacuy/pointnetvlad">
        PointNetVLAD: Deep Point Cloud Based Retrieval for Large-Scale Place Recognition</a></strong>
        <br>
        <u>Mikaela Angelina Uy</u>, Gim Hee Lee<br>
        <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2018 <br>
        <span class="links">
        <a href="https://arxiv.org/pdf/1804.03492.pdf">Paper</a>
        <a href="https://github.com/mikacuy/pointnetvlad">Code</a>
        <a href="https://drive.google.com/open?id=1u4lXs9fTJGz_Ch05LeBqi8nT3o96V8OD">Poster</a>
        </span> </p>
      </div>
    </div> -->


  </div>
</div>
</div>

<!-- ############################################## -->
<div class="container">
<div class="row mb-3" style="padding-bottom: 25px;">

  <div class="col-12 pt-3  px-4 pb-4   bubble offset-xl-1 col-xl-10" >

  <!-- ####################### Awards ####################### -->
  <h2>Work Experiences</h2>

  <div class="publication media">
      <!-- <div class="publication media d-flex flex-column flex-md-row mb-5"> -->
            <!-- <div class="resume-content mr-auto"> -->
      <img src="{{ base_path }}/assets/images/google-logo.png" class="publogo img-fluid float-left rounded g" width="75" <="" a=""> 
      <div class="media-body">            
        <h3 class="mb-0">Research Intern, Google</h3>
        <div class="subheading mb-3">June 2023 - present</div>
                         
        Mentors:
        <a target="_blank" href="https://www.sfu.ca/~keli/"> Ke Li</a>, <a target="_blank" href="https://roxanneluo.github.io/"> Xuan Luo</a>
      </div>
  </div>

  <div class="publication media">
      <!-- <div class="publication media d-flex flex-column flex-md-row mb-5"> -->
            <!-- <div class="resume-content mr-auto"> -->
      <img src="{{ base_path }}/assets/images/google-logo.png" class="publogo img-fluid float-left rounded g" width="75" <="" a=""> 
      <div class="media-body">            
        <h3 class="mb-0">Research Intern, Project Starline, Google</h3>
        <div class="subheading mb-3">June 2022 - January 2023</div>
                         
        Mentors:
        <a target="_blank" href="https://www.sfu.ca/~keli/"> Ke Li</a>, Mirko Visontai 
      </div>
  </div>

  <div class="publication media">
      <!-- <div class="publication media d-flex flex-column flex-md-row mb-5"> -->
            <!-- <div class="resume-content mr-auto"> -->
      <img src="{{ base_path }}/assets/images/autodesk.png" class="publogo img-fluid float-left rounded g" width="75" <="" a=""> 
      <div class="media-body">            
        <h3 class="mb-0">Research Intern, Autodesk AI Lab</h3>
        <div class="subheading mb-3">June - September 2021</div>
                         
        Mentors:
        <a target="_blank" href="https://www.autodesk.com/research/people/joseph-lambourne"> Joseph Lambourne</a>
      </div>
  </div>

  <div class="publication media">
      <!-- <div class="publication media d-flex flex-column flex-md-row mb-5"> -->
            <!-- <div class="resume-content mr-auto"> -->
      <img src="{{ base_path }}/assets/images/adobe_logo.png" class="publogo img-fluid float-left rounded g" width="75" <="" a=""> 
      <div class="media-body">            
        <h3 class="mb-0">Research Intern, Creative Intelligence Lab, Adobe Research</h3>
        <div class="subheading mb-3">June - September 2020</div>
                         
        Mentors:
        <a target="_blank" href="http://www.vovakim.com"> Vladimir G. Kim</a>,  
        <a target="_blank" href="https://mhsung.github.io"> Minhyuk Sung</a>, 
        <a target="_blank" href="https://noamaig.github.io"> Noam Aigerman</a>, 
        <a target="_blank" href="https://www.cse.iitb.ac.in/~sidch/"> Siddhartha Chaudhuri</a> 
      </div>
  </div>

  <div class="publication media">
      <!-- <div class="publication media d-flex flex-column flex-md-row mb-5"> -->
            <!-- <div class="resume-content mr-auto"> -->
      <img src="{{ base_path }}/assets/images/hkust_logo.png" class="publogo img-fluid float-left rounded g" width="75" <="" a=""> 
      <div class="media-body">            
        <h3 class="mb-0"> <br> Research Assistant, Vision & Graphics Group, HKUST</h3>
        <div class="subheading mb-3">September 2018 - June 2019</div>
                         
        Mentors:
        <a target="_blank" href="http://www.saikit.org"> Prof. Sai-Kit Yeung</a>,  
        <a target="_blank" href="https://sonhua.github.io"> Binh-Son Hua</a>, 
        <a target="_blank" href="https://ducthanhnguyen.weebly.com"> Duc Thanh Nguyen</a> 
      </div>
  </div>

  </div>
</div>
</div>
<!-- ############################################## -->

<!-- ############################################## -->
<div class="container">
<div class="row mb-3">

  <div class="col-12 pt-3  px-4 pb-4   bubble offset-xl-1 col-xl-10">

  <!-- ####################### Awards ####################### -->
  <h2>Invited Talks</h2>
    <div class="awards">
    <ul> 
      <li>Simon Fraser Univeristy Visual Computing Seminar, June 26, 2023, Towards Controllable 3D Content Creation by Leveraging Geometric Priors</li>
      <li><a target="_blank" href="https://struco3d.github.io/cvpr2023/">Structural and Compositional Learning on 3D Data</a>, CVPR 2023 Workshop, June 18, 2023, Towards Controllable 3D Content Creation by Leveraging Geometric Priors</li>
      <li>KAIST, January 9, 2023, SCADE: NeRFs from Space CArving with Ambiguity-Aware Depth Estimates</li>     
      <li>VinAI Seminar Series, July 22, 2022, Learning to Vary 3D Models for Universally Accessible 3D Content Creation</li>
      <li>Brown Vision Computing Seminar, April 11, 2022, Learning to Vary 3D Models for Universally Accessible 3D Content Creation</li>
      <li>Stanford G-Cafe, March 10, 2022, Point2Cyl: Reverse Engineering 3D Objects from Point Clouds to Extrusion Cylinders</li>
    </ul>
    </div>

  </div>
</div>
</div>
<!-- ############################################## -->

<!-- ############################################## -->
<div class="container">
<div class="row mb-3">

  <div class="col-12 pt-3  px-4 pb-4   bubble offset-xl-1 col-xl-10">

  <!-- ####################### Awards ####################### -->
  <h2>Teaching Experiences</h2>
    <div class="awards">
    <ul>
      <li>Stanford CS 348n Guest Lecture, May 31, 2023, Neural Radiance Fields: Sparse View and Dynamic Scenes</li> 
      <li>Stanford CS 348n Guest Lecture, May 24, 2023, Continuous and Discrete Shape Edits/Deformations</li>
      <li>Stanford CS 348n Guest Lecture, February 16, 2022, Neural Shape Variation and Generation</li>
      <li>Teaching Assistant, Winter 2021, <a target="_blank" href="http://graphics.stanford.edu/courses/cs348a-21-winter/">Computer Graphics: Geometric Modeling/Processing (CS 348a)</a>, Stanford University</li>
    </ul>
    </div>

  </div>
</div>
</div>
<!-- ############################################## -->

<!-- ############################################## -->
<div class="container">
<div class="row mb-3">

  <div class="col-12 pt-3  px-4 pb-4   bubble offset-xl-1 col-xl-10">

  <!-- ####################### Awards ####################### -->
  <h2>Selected Awards</h2>
    <div class="awards">
    <ul>
      <li><a target="_blank" href="https://machinelearning.apple.com/updates/apple-scholars-aiml-2023">Apple Scholars in AI/ML PhD Fellowship</a>, <em> 2023</em> </li>      
      <li><a target="_blank" href="https://research.snap.com/fellowships">Snap Research Fellowship</a>, <em> 2022</em> </li>
      <li><a target="_blank" href="https://research.facebook.com/blog/2023/4/announcing-the-2023-meta-research-phd-fellowship-award-winners/">Meta PhD Fellowship Finalist</a>, <em> 2023</em> </li>
      <li>School of Engineering Fellowship, <em>Stanford University, 2019-2020</em> </li>
      <li>HKSAR Government Targeted Scholarship (Full 4-year university scholarship)</li>
      <li>NUS Graduate Scholarship for ASEAN Nationals (Full masters scholarship)</li>
      <li>Google Women Techmakers Scholarship, <em>2016</em></li>
      <li>Epsilon Fund Award, <em>HKUST Mathematics Department, 2017</em></li>
      <li>International Mathematical Olympiad (IMO) Bronze Medalist, <em>2012, 2013</em></li>
      <li>Philippine Mathematical Olympiad 1st runner-up, <em>2012, 2013</em></li>
    </ul>
    </div>

  </div>
</div>
</div>
<!-- ############################################## -->

<!-- ############################################## -->
<div class="container">
<div class="row mb-3">

  <div class="col-12 pt-3  px-4 pb-4   bubble offset-xl-1 col-xl-10">

  <!-- ####################### Awards ####################### -->
  <h2>Projects</h2>
  <div class="projects">
      <div class="projects d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <img src="{{ base_path }}/assets/images/cs229_poster.png" class="publogo img-fluid float-left rounded g" width="200" <="" a="">            
              <h3 class="mb-0">Interpretable & Actionable Models using Attribute & Uncertainty Information</h3>
              <div class="subheading mb-3">CS229 project, Autumn 2019</div>

              <ul>
                <li> Deep-learning models can be difficult to understand and control intuitively due to the black-box nature of these models. However, such lack of interpretability and human actionability in the models’ decision processes make it difficult to trust these models in critical applications that affect the lives of people. We propose to alleviate these problems through the use of attribute and uncertainty models in deep networks.</li>
              </ul> 
                               
                Links:
                <a target="_blank" href="{{ base_path }}/assets/papers/CS229_Final_Report.pdf"> Report</a> 
                <a target="_blank" href="{{ base_path }}/assets/poster/cs229_poster.pdf"> Poster</a> 
            </div>
      </div>

      <div class="projects d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <img src="{{ base_path }}/assets/images/epoxsea_logo.png" class="publogo img-fluid float-left rounded g" width="200" <="" a="">            
              <h3 class="mb-0">HKUST Robotics Team, Remotely Operated Vehicle (ROV) Subteam</h3>
              <div class="subheading mb-3">Software Engineer, 2014-2015</div>
                  <ul>
                    <li><b>Overall 3rd Place </b> (Explorer Class) – 14th Annual MATE International Underwater
                          Robotics Competition in <em>St John’s, Newfoundland and Labrador, Canada</em></li>
                    <li><b>Asia Champion</b> in 2015 MATE Asia Regional Underwater Robotics Competition</li>
                    <li>Built the main control software of the ROV, which operates with ROS and is controlled with an Xbox controller, and Qt GUI’s for the competition runs</li>
                    <li>The team is composed of 15 engineers who built and designed the ROV from scratch.</li>
                  </ul>
                Links:
                <a target="_blank" href="https://www.youtube.com/watch?v=tYRYdTxP_7Y"> Video </a> 
            </div>
      </div>

      <div class="projects d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">     
              <h3 class="mb-0">Underwater Object Detection</h3>
              <div class="subheading mb-3">Undergraduate Thesis, HKUST</div>
                  <ul>
                    <li>Advised by <a href="http://www.cs.ust.hk/~cktang/">Prof. Chi-Keung Tang</a></li>
                    <li>Studied the performance of real-time object detection models, both using handcrafted
                    features and deep learning networks, for underwater diver detection in robotics applications</li>
                  </ul>
                Links:
                <a target="_blank" href="{{ base_path }}/assets/poster/FYT_poster.pdf"> Poster </a> 
            </div>
      </div>


  </div>

  </div>
</div>
</div>
<!-- ############################################## -->

<!-- ############################################## -->
<div class="container">
<div class="row mb-3">

  <div class="col-12 pt-3  px-4 pb-4   bubble offset-xl-1 col-xl-10">

  <!-- ####################### Awards ####################### -->
  <h2>Hobbies and Interests</h2>
    <div class="hobbies">
    <p>
      For most of my pre-university life, I was into competitive mathematics, with geometry being a favorite topic. I competed in various math competitions both local and abroad representing the Philippine Team. During my spare time back at home, I now train elementary and high school students for international math competitions. I was part of the training team of the 2017-2020 PH IMO team, and I led the PH team to a number of elementary math competitions. <br>
      <br>
      I also enjoy playing soccer, frisbee and scuba diving. I was part of the HKUST Women's Soccer Team back in my senior year.

    </p>
    </div>

  </div>
</div>
</div>
<!-- ############################################## -->

<!-- ############################################## -->
<div class="container">
<div class="row mb-3">

  <div class="col-12 pt-3  px-4 pb-4   bubble offset-xl-1 col-xl-10">

  <!-- ####################### Awards ####################### -->
  <h2>Academic Services</h2>
    <div class="hobbies">
    
    <p>
      Reviewer: CVPR, ICCV, ECCV, SIGGRAPH, SIGGRAPH Asia, BMVC, 3DV, AAAI, TVCG, Eurographics, Neurips
    </p>

    </div>

  </div>
</div>
</div>
<!-- ############################################## -->


